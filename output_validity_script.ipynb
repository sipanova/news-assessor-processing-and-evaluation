{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78236e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [\n",
    "#     \"gpt-4o-12q\",\n",
    "#     \"granite-3-3-8b-6q\",\n",
    "#     \"llama-3-2-3b-6q\",\n",
    "#     \"mistral-nemo-6q\",\n",
    "#     \"mistral-nemo-12q\",\n",
    "#     \"mistral-7b-0-1-6q\",\n",
    "#     \"mistral-7b-0-1-12q\",\n",
    "#     \"mistral-7b-0-3-6q\"\n",
    "#     ]\n",
    "\n",
    "\n",
    "models = [\n",
    "    \"granite-3-3-8b-6q\",\n",
    "    \"llama-3-2-3b-6q\",\n",
    "    \"mistral-nemo-6q\",\n",
    "    \"mistral-7b-0-1-6q\",\n",
    "    \"mistral-nemo-post-6q\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04e706f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "precision_recall_excel_sheet_template = {\n",
    "    'name': '',\n",
    "    'precision_recall_df': pd.DataFrame()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "916d4457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "excel_sheet_template = {\n",
    "    'name': '',\n",
    "    'acc_data': pd.DataFrame(),\n",
    "    'val_data': pd.DataFrame()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c77d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_12 = [\n",
    "        'overall_sentiment', 'nature_dimension', 'nature_sentiment', 'functional_dimension', 'functional_sentiment',\n",
    "        'normative_dimension', 'normative_sentiment', 'cultural_dimension', 'cultural_sentiment',\n",
    "        'disinformation_type', 'disinformation_technique'\n",
    "    ]\n",
    "\n",
    "columns_6 = [\n",
    "        'overall_sentiment',  'nature_sentiment',  'functional_sentiment', 'normative_sentiment', 'cultural_sentiment',\n",
    "        'disinformation_type'\n",
    "    ]\n",
    "\n",
    "columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16fafe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "santements = ['very negative', 'negative', 'neutral', 'positive', 'very positive', 'No Sentiment']\n",
    "\n",
    "natural_dimensions = ['Nature Dimension not addressed', 'Landscape/scenery', 'Geography', 'Weather/climate', 'Preserved nature', 'Nature activities', 'Other aspect of Nature dimension']\n",
    "functional_dimensions = ['Functional Dimension not addressed', 'Education system', 'Science/innovation', 'Products', 'Economy', 'Infrastructure', 'Politics', 'Living/working conditions', 'Security', 'Other aspect of Functional dimension']\n",
    "normative_dimensions = ['Normative Dimension not addressed', 'Environmental protection', 'Freedom/human rights', 'Civil rights', 'International engagement', 'Ethical issues/scandals', 'Conflict avoidance', 'Tolerance/openness', 'Other aspect of Normative dimension']\n",
    "cultural_dimensions = ['Cultural Dimension not addressed', 'Sports', 'Food', 'Cultural offer', 'Personalities', 'Traditions', 'History', 'Cultural diversity', 'Other aspect of Culture dimension']\n",
    "disinformation_type = ['No disinformation type', 'False connection', 'False context', 'Misleading content', 'Fabricated content', 'Manipulated content', 'Other disinformation type']\n",
    "disinformation_technique = ['No disinformation technique', 'Ad hominem attack', 'Emotional language', 'False dichotomies', 'Incoherence', 'Scapegoating', 'Other disinformation technique']\n",
    "\n",
    "valid_options = santements + natural_dimensions + functional_dimensions + normative_dimensions + cultural_dimensions + disinformation_type + disinformation_technique\n",
    "\n",
    "valid_options = [x.lower().strip().rstrip('.') for x in valid_options]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d84db0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3eb6bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_labels(col_name):\n",
    "    match col_name:\n",
    "        case \"overall_sentiment\":\n",
    "            return santements\n",
    "        case \"nature_dimension\":\n",
    "            return natural_dimensions\n",
    "        case \"nature_sentiment\":\n",
    "            return santements\n",
    "        case \"functional_dimension\":\n",
    "            return functional_dimensions\n",
    "        case \"functional_sentiment\":\n",
    "            return santements\n",
    "        case \"normative_dimension\":\n",
    "            return normative_dimensions\n",
    "        case \"normative_sentiment\":\n",
    "            return santements\n",
    "        case \"cultural_dimension\":\n",
    "            return cultural_dimensions\n",
    "        case \"cultural_sentiment\":\n",
    "            return santements\n",
    "        case \"disinformation_type\":\n",
    "            return disinformation_type\n",
    "        case \"disinformation_technique\":\n",
    "            return disinformation_technique\n",
    "        case _:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c8e4901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_normalization(str_value):\n",
    "    if isinstance(str_value, str):\n",
    "        return str_value.lower().strip().rstrip('.')\n",
    "    else:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "220d0633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(input_str):\n",
    "    if string_normalization(input_str) in valid_options:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04c5a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# question_model_path = 'question_model_1'\n",
    "question_model_path = 'question_model_2'\n",
    "# question_model_path = 'question_model_2_with_parameters'\n",
    "\n",
    "def get_models_files(model_path):\n",
    "    try:\n",
    "        path = Path(f'data/{question_model_path}/{model_path}')\n",
    "        file_list = [f.name for f in path.iterdir() if f.is_file()]\n",
    "        prefix = f\"data/{question_model_path}/{model_path}/\"\n",
    "        prefixed_file_list = [prefix + s for s in file_list]\n",
    "        return prefixed_file_list\n",
    "    except Exception as e:\n",
    "        print(\"An unexpected error occurred in get_models_files:\", e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "31fa39f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# def print_line():\n",
    "#     print(\"--------------------------------------------\")\n",
    "    \n",
    "input_file_path = f'data/final_file_mistral_nemo__post_1_133_2025-06-20_14-53-44.csv'\n",
    "llm_values = pd.read_csv(input_file_path)\n",
    "referance_file_path = 'data/valid_test_final_file.csv'\n",
    "referance_values = pd.read_csv(referance_file_path)\n",
    "\n",
    "if len(llm_values.columns) == 22:\n",
    "    columns = columns_12\n",
    "else:\n",
    "    columns = columns_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4fa211b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision and recall\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "labels = []\n",
    "\n",
    "precision_recall_excel_sheets = []\n",
    "\n",
    "for model in models:\n",
    "    file_list = get_models_files(model_path=model)\n",
    "    precision_recall_df = pd.DataFrame(columns=[\n",
    "        'question',\n",
    "        'label',\n",
    "        'precision',\n",
    "        'recall',\n",
    "        'TP',\n",
    "        'FP',\n",
    "        'FN',\n",
    "        'exp_id'\n",
    "        ])\n",
    "    for file_index, file_path in enumerate(file_list):\n",
    "        llm_values = pd.read_csv(file_path)\n",
    "        if len(llm_values.columns) == 22:\n",
    "            columns = columns_12\n",
    "        else:\n",
    "            columns = columns_6\n",
    "\n",
    "        for col in columns:\n",
    "            y_pred = llm_values[col]\n",
    "            y_ref = referance_values[col]\n",
    "            labels = find_labels(col)\n",
    "\n",
    "            for label in labels:\n",
    "                tp = 0  # True Positives\n",
    "                fp = 0  # False Positives\n",
    "                fn = 0  # False Negatives\n",
    "                for i in range(len(y_pred)):\n",
    "                    predicted = string_normalization(y_pred[i])\n",
    "                    actual = string_normalization(y_ref[i])\n",
    "                    val_label = string_normalization(label)\n",
    "\n",
    "                    if predicted == val_label and actual == val_label:\n",
    "                        tp += 1\n",
    "                    elif predicted == val_label and actual != val_label:\n",
    "                        fp += 1\n",
    "                    elif predicted != val_label and actual == val_label:\n",
    "                        fn += 1\n",
    "\n",
    "                # Calculate precision and recall\n",
    "                if tp + fp > 0:\n",
    "                    precision = round(tp*100 / (tp + fp),2)\n",
    "                else:\n",
    "                    precision = 0.00\n",
    "\n",
    "                if tp + fn > 0:\n",
    "                    recall = round(tp*100 / (tp + fn),2)\n",
    "                else:\n",
    "                    recall = 0.00\n",
    "\n",
    "                precision_recall_df.loc[len(precision_recall_df)] = [col, label, precision, recall, tp, fp, fn, file_index]\n",
    "                \n",
    "        \n",
    "    excel_sheet = deepcopy(precision_recall_excel_sheet_template)\n",
    "    excel_sheet['name'] = model\n",
    "    excel_sheet['precision_recall_df'] = precision_recall_df\n",
    "    precision_recall_excel_sheets.append(excel_sheet)\n",
    "\n",
    "with pd.ExcelWriter('precision_recall_all.xlsx', engine='xlsxwriter') as writer:\n",
    "    for sheet in precision_recall_excel_sheets:\n",
    "        sheet_name = sheet['name']\n",
    "        sheet['precision_recall_df'].to_excel(writer, sheet_name=f\"{sheet_name}\", index=False)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c29c06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all accuracies\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "excel_sheets = []\n",
    "\n",
    "for model in models:\n",
    "    file_list = get_models_files(model_path=model)\n",
    "    val_df = pd.DataFrame()\n",
    "    acc_df = pd.DataFrame()\n",
    "    for file_index, file_path in enumerate(file_list):\n",
    "        llm_values = pd.read_csv(file_path)\n",
    "        if len(llm_values.columns) == 22:\n",
    "            columns = columns_12\n",
    "        else:\n",
    "            columns = columns_6\n",
    "\n",
    "        if \"Columns\" not in val_df.columns:\n",
    "            val_df[\"Columns\"] = columns\n",
    "\n",
    "        if \"Columns\" not in acc_df.columns:\n",
    "            acc_df[\"Columns\"] = columns\n",
    "\n",
    "        val_df[f'Exp_{file_index+1}'] = 0.0\n",
    "        \n",
    "        for col in columns:\n",
    "\n",
    "            valid_values = 0\n",
    "            accurate_values = 0\n",
    "            \n",
    "            for index, row in llm_values.iterrows():\n",
    "                try:\n",
    "                    value = llm_values.at[index, col]\n",
    "                    if isinstance(value, str):\n",
    "                        if is_valid(value):\n",
    "                            valid_values += 1\n",
    "                except Exception as e:\n",
    "                    print(\"An unexpected error occurred col:\", e)\n",
    "            val_df.loc[val_df['Columns'] == col, f'Exp_{file_index+1}'] = round(valid_values*100/len(llm_values),2)\n",
    "\n",
    "\n",
    "            accurate_values = 0\n",
    "            for index, row in referance_values.iterrows():\n",
    "                try:\n",
    "                    referance_value = referance_values.at[index, col]\n",
    "                    llm_value = llm_values.at[index, col]\n",
    "                    if isinstance(referance_value, str) and isinstance(llm_value, str):\n",
    "                        referance_value = referance_value.lower().strip().rstrip('.')\n",
    "                        llm_value = llm_value.lower().strip().rstrip('.')\n",
    "                        if referance_value == llm_value:\n",
    "                            accurate_values += 1\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "            acc_df.loc[acc_df['Columns'] == col, f'Exp_{file_index+1}'] = round(accurate_values*100/len(llm_values),2)\n",
    "\n",
    "    acc_df['Mean'] = acc_df[['Exp_1', 'Exp_2', 'Exp_3', 'Exp_4', 'Exp_5']].mean(axis=1).round(2)\n",
    "    acc_df['StD'] = acc_df[['Exp_1', 'Exp_2', 'Exp_3', 'Exp_4', 'Exp_5']].std(axis=1).round(2)\n",
    "\n",
    "    val_df['Mean'] = val_df[['Exp_1', 'Exp_2', 'Exp_3', 'Exp_4', 'Exp_5']].mean(axis=1).round(2)\n",
    "    val_df['StD'] = val_df[['Exp_1', 'Exp_2', 'Exp_3', 'Exp_4', 'Exp_5']].std(axis=1).round(2)\n",
    "\n",
    "    excel_sheet = deepcopy(excel_sheet_template)\n",
    "    excel_sheet['name'] = model\n",
    "    excel_sheet['acc_data'] = acc_df\n",
    "    excel_sheet['val_data'] = val_df\n",
    "    excel_sheets.append(excel_sheet)\n",
    "\n",
    "pass\n",
    "with pd.ExcelWriter('all_accuracy.xlsx', engine='xlsxwriter') as writer:\n",
    "    for sheet in excel_sheets:\n",
    "        sheet_name = sheet['name']\n",
    "        sheet['val_data'].to_excel(writer, sheet_name=f\"val_{sheet_name}\", index=False)\n",
    "        sheet['acc_data'].to_excel(writer, sheet_name=f\"acc_{sheet_name}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d7c41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e80d6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 133\n",
      "Valid overall_sentiment: 94.74 %.\n",
      "Valid nature_sentiment: 84.21 %.\n",
      "Valid functional_sentiment: 84.21 %.\n",
      "Valid normative_sentiment: 84.21 %.\n",
      "Valid cultural_sentiment: 84.21 %.\n",
      "Valid disinformation_type: 84.21 %.\n",
      "Avg validity: 85.96 %.\n"
     ]
    }
   ],
   "source": [
    "print(f'Data length: {len(llm_values)}')\n",
    "all_vals = 0\n",
    "for col in columns:\n",
    "    valid_values = 0\n",
    "    for index, row in llm_values.iterrows():\n",
    "        try:\n",
    "            value = llm_values.at[index, col]\n",
    "            if isinstance(value, str):\n",
    "                if is_valid(value):\n",
    "                    valid_values += 1\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    val = round(valid_values*100/len(llm_values),2)\n",
    "    all_vals += val\n",
    "    print(f\"Valid {col}: {val} %.\")\n",
    "\n",
    "print(f\"Avg validity: {round(all_vals/len(columns),2)} %.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e62a3c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_sentiment accuracy: 42.86 %.\n",
      "nature_sentiment accuracy: 64.66 %.\n",
      "functional_sentiment accuracy: 41.35 %.\n",
      "normative_sentiment accuracy: 39.1 %.\n",
      "cultural_sentiment accuracy: 48.12 %.\n",
      "disinformation_type accuracy: 78.2 %.\n",
      "Avg accuracy: 52.38 %.\n"
     ]
    }
   ],
   "source": [
    "all_accuracies = 0\n",
    "for col in columns:\n",
    "    accurate_values = 0\n",
    "    for index, row in referance_values.iterrows():\n",
    "        try:\n",
    "            referance_value = referance_values.at[index, col]\n",
    "            llm_value = llm_values.at[index, col]\n",
    "            if isinstance(referance_value, str) and isinstance(llm_value, str):\n",
    "                referance_value = referance_value.lower().strip().rstrip('.')\n",
    "                llm_value = llm_value.lower().strip().rstrip('.')\n",
    "                if referance_value == llm_value:\n",
    "                    accurate_values += 1\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    accuracy = round(accurate_values*100/len(referance_values),2)        \n",
    "    all_accuracies += accuracy\n",
    "    \n",
    "    print(f\"{col} accuracy: {accuracy} %.\")\n",
    "\n",
    "print(f\"Avg accuracy: {round(all_accuracies/len(columns),2) } %.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
